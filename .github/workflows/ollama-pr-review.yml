name: PR Summarizer

on:
  pull_request:
    types: [opened, synchronize, reopened, edited]

jobs:
  summarize-pr:
    runs-on: ubuntu-latest
    env:
      OLLAMA_MODELS: ${{ github.workspace }}/.ollama-models

    steps:
      # 1Ô∏è‚É£ Checkout repo
      - name: Checkout repo
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Cache Ollama models directory
      - name: Cache Ollama models
        uses: actions/cache@v4
        with:
          path: .ollama-models
          key: ollama-models-${{ runner.os }}-v1
          restore-keys: |
            ollama-models-${{ runner.os }}-

      # 3Ô∏è‚É£ Install Ollama
      - name: Install Ollama
        run: |
          if ! command -v ollama &> /dev/null; then
            curl -fsSL https://ollama.com/install.sh | sh
          else
            echo "‚úÖ Ollama already installed"
          fi

      # 4Ô∏è‚É£ Ensure llama3.2 model is present
      - name: Ensure llama3.2 model
        run: |
          mkdir -p "$OLLAMA_MODELS"

          echo "üöÄ Starting Ollama server..."
          ollama serve > /tmp/ollama.log 2>&1 &
          OLLAMA_PID=$!
          sleep 10

          if ollama list 2>/dev/null | grep -q "llama3.2"; then
            echo "‚úÖ Model already available"
          else
            echo "‚¨áÔ∏è Pulling llama3.2:latest..."
            ollama pull llama3.2:latest || (echo "‚ùå Pull failed"; cat /tmp/ollama.log; exit 1)
          fi

          kill $OLLAMA_PID || true
          echo "üìÇ Models directory contents:"
          ls -Rlh "$OLLAMA_MODELS"

      # 5Ô∏è‚É£ Get PR content
      - name: Get PR content
        id: pr
        uses: actions/github-script@v7
        with:
          script: |
            const pr = context.payload.pull_request
            return {
              title: pr.title,
              body: pr.body,
              url: pr.html_url
            }

      # 6Ô∏è‚É£ Generate PR summary
      - name: Run PR Summarizer
        run: |
          echo "üöÄ Starting Ollama server..."
          ollama serve > /tmp/ollama.log 2>&1 &
          OLLAMA_PID=$!
          sleep 10

          PROMPT="Review this pull request:\n\nTitle: ${{ steps.pr.outputs.title }}\n\nDescription: ${{ steps.pr.outputs.body }}\n\nURL: ${{ steps.pr.outputs.url }}\n\nProvide suggestions for improvement, coding best practices, readability improvements. Give an overall rating: ‚úÖ Looks good | ‚ö†Ô∏è Needs attention | ‚ùå Needs major changes. Output in markdown with tables summarizing the files changed."

          echo -e "$PROMPT" | ollama run llama3.2:latest > pr-summary.txt

          kill $OLLAMA_PID || true
          cat pr-summary.txt

      # 7Ô∏è‚É£ Post PR summary as a comment
      - name: Post PR summary comment
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: "ü§ñ PR Summary"
          message: |
            Here‚Äôs an AI-generated summary:

            ```
            $(cat pr-summary.txt)
            ```
