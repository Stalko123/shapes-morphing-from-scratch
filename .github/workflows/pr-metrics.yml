name: AI PR Summary with Persistent Cache
on:
  pull_request:
    types: [opened, synchronize, reopened]

env:
  OLLAMA_MODEL: deepseek-coder:latest

jobs:
  pr-summary:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup assets
        run: |
          mkdir -p ./assets
          echo "$OLLAMA_MODEL" > ./assets/models-file.txt
          # [contenu du prompt-file.txt comme précédemment]

      - name: Restore Ollama cache
        uses: actions/cache/restore@v3
        id: restore-ollama-cache
        with:
          path: |
            ~/.ollama
            /usr/local/bin/ollama
          key: ollama-${{ runner.os }}-${{ hashFiles('assets/models-file.txt') }}
          restore-keys: |
            ollama-${{ runner.os }}-

      - name: Install Ollama if not cached
        if: steps.restore-ollama-cache.outputs.cache-hit != 'true'
        run: |
          curl -fsSL https://ollama.ai/install.sh | sh
          mkdir -p ~/.ollama

      - name: Start Ollama service
        run: |
          pkill -f ollama || true
          sleep 2
          nohup ollama serve &
          sleep 15
          # Attendre que le service soit opérationnel
          timeout 60 bash -c 'until curl -s http://localhost:11434/api/tags > /dev/null; do sleep 2; done'

      - name: Check and pull model if needed
        run: |
          # Vérifier si le modèle est déjà installé
          if ! curl -s http://localhost:11434/api/tags | grep -q "$(echo $OLLAMA_MODEL | cut -d':' -f1)"; then
            echo "Pulling model $OLLAMA_MODEL..."
            ollama pull $OLLAMA_MODEL
          else
            echo "Model $OLLAMA_MODEL already installed"
          fi

      - name: Run AI summarizer
        uses: behrouz-rad/ai-pr-summarizer@v1
        with:
          llm-model: ${{ env.OLLAMA_MODEL }}
          prompt-file: ./assets/prompt-file.txt
          models-file: ./assets/models-file.txt
          version-file: ./assets/version-file.txt
          context-window: 4096
          upload-changes: true
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Save Ollama cache
        uses: actions/cache/save@v3
        if: always()
        with:
          path: |
            ~/.ollama
            /usr/local/bin/ollama
          key: ollama-${{ runner.os }}-${{ hashFiles('assets/models-file.txt') }}-${{ hashFiles('assets/version-file.txt') }}
